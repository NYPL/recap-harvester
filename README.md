# ReCAP Harvester

This application is a poller in the Data/Search pipeline of NYPL's Library Services Platform. It polls an S3 bucket (formerly an SFTP server) managed by SCSB for additions, updates, and deletions of partner records. It processes SCSBXML and json files and broadcasts Bib and Item documents into the `BibPostRequest-[env]` and `ItemPostRequest-[env]` streams just as our [Sierra Retriever](https://github.com/NYPL-discovery/sierra-retriever/) does for our own records. This app is represented by the "RecapHarvester" component in our [Data/Search Architecture diagram](https://docs.google.com/presentation/d/1kPUhT-JPOuniXndKWc_JEp2EY5rOPuH5ebSqYCe_438/edit#slide=id.g401dec0f26_0_128).

## Setup

This is a Java app built by [Apache Maven](https://maven.apache.org/what-is-maven.html).

To install Maven on OSX using [Homebrew](https://brew.sh/):

```
brew install mvn
```

You probably need to be running Java8 (as reported by `java -version`). To enable Java8 on OSX:

 * `brew install openjdk@8`
 * `echo 'export PATH="/usr/local/opt/openjdk@8/bin:$PATH"' >> ~/.zshrc`
 * `source ~/.zshrc`
 * `java -version` should report something like "openjdk version "1.8.0_312"

(Note, the above will link `java` to v1.8 for all other processes on your machine until you remove the added line from `~/.zshrc`.)

To compile and run all tests after modifying code:

```
mvn clean package
```

The environmental config you'll need to set up depends on the mode in which you run the app, covered below.

Note on configuring logging: It's not clear how to modify the log level of this app via an environmental variable. It's stuck at level `INFO`.

## When does this app run?

This app can be run in 2 different modes.

1. **Nightly Updates**: On a [nightly basis](#nightly-updates-mode), it downloads HTC-generated files that represent bibliographic additions, updates, and deletions.
1. **Bulk**: The [initial seeding of our databases & index](#bulk) from a massive zip of our partners' items generated by HTC. (Note: This was done at product launch and not retested since. We're not likely to need to do this again unless/until we have a very large influx of partner records to update.)

### "Nightly Updates" Mode

The app connects to an S3 bucket (formerly an SFTP server) managed by SCSB to retrieve partner bib and item metadata updates. It uses [Apache Camel](https://camel.apache.org/), a streaming framework, to manage the following rough pipeline:
 * Additions & Updates:
   * Fetch zipped SCSBXml documents representing additions and updates for partner records from S3 bucket in `data-exports/NYPL/SCSBXml/Incremental/*.zip`
   * (Move the processed zips to `data-exports/NYPL/SCSBXml/Incremental.processed` in the same bucket so that we don't process them again.)
   * Unzip the SCSBXML documents and write them locally
   * Iterate over the local SCSBXML documents, translate them into Bib and Item documents
   * Broadcast the Bib and Item documents over `BibPostRequest-[env]` and `ItemPostRequest-[env]` Kinesis streams, respectively (Avro encoded using namesake schemas)
 * Deletions:
   * Fetch zipped JSON documents representing deleted ("deaccessioned") partner bibs and items from `data-exports/NYPL/Json/*.zip`
   * (Move the processed zips to `data-exports/NYPL/Json.processed` in the same bucket so that we don't process them again.)
   * Unzip the enclosed JSON documents and write them locally
   * Iterate over the json files, translate them into Bib and Item documents with `"deleted": true`
   * Broadcast the "deleted" documents over `BibPostRequest-[env]` and `ItemPostRequest-[env]` Kinesis streams (Avro encoded using namesake schemas)

#### Alarm

The app is monitored by a [CW alarm](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#alarmsV2:alarm/RecapHarvesterNotProcessingBibs-production). The alarm is configured to fire when the [RecapHarvesterBibProcessed-Production CW metric](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#metricsV2?graph=~(metrics~(~(~'LogMetrics~'RecapHarvesterBibProcessed-Production))~view~'timeSeries~stacked~false~region~'us-east-1~start~'-PT168H~end~'P0D~stat~'Sum~period~86400)&query=~'*7bLogMetrics*7d*20RecapHarvesterBibProcessed*20MetricName*3d*22RecapHarvesterBibProcessed-Production*22) <= 0 for 1 day. That metric is a proxy for [a custome metric filter](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logsV2:log-groups/log-group/$252Faws$252Felasticbeanstalk$252Fnightly-recap-harvester-production$252Fvar$252Fapp$252Fcurrent$252Frecap-harvester$252Frecap-logging.log$23metric-filters
) defined on the recap-harvester logs looking for the phrase "Processing bib - recap-" in the logs. In summary:
 - the app [logs out](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logsV2:log-groups/log-group/$252Faws$252Felasticbeanstalk$252Fnightly-recap-harvester-production$252Fvar$252Fapp$252Fcurrent$252Frecap-harvester$252Frecap-logging.log/log-events$3FfilterPattern$3D$2522Processing+bib+-+recap-$2522$26start$3D-172800000) "Processing bib - recap-"
 - a [metric filter](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logsV2:log-groups/log-group/$252Faws$252Felasticbeanstalk$252Fnightly-recap-harvester-production$252Fvar$252Fapp$252Fcurrent$252Frecap-harvester$252Frecap-logging.log$23metric-filters) turns that into [a metric](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#metricsV2?graph=~(metrics~(~(~'LogMetrics~'RecapHarvesterBibProcessed-Production))~view~'timeSeries~stacked~false~region~'us-east-1~start~'-PT168H~end~'P0D~stat~'Sum~period~86400)&query=~'*7bLogMetrics*7d*20RecapHarvesterBibProcessed*20MetricName*3d*22RecapHarvesterBibProcessed-Production*22)
 - an [alarm](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#alarmsV2:alarm/RecapHarvesterNotProcessingBibs-production) fires when the metric isn't written to for 1 day.

The alarm fires a lot due to:
 - SCSB drops the incrementals at slightly different times. The recap-harvester process them immediately after. If the app processes the morning batch at 9:30 UTC on one day and 11:00 UTC on the next day, the alarm will fire at 9:30 UTC on the second day. It will return to OK shortly after 11:00 UTC when it starts seeing new writes. We are not able to increase the period to, say 26 hours because "Metrics cannot be checked across more than a day (EvaluationPeriods * Period must be <= 86400)"
 - Sometimes there are legitimately no updates from SCSB for a day or two - particularly on the weekend.

#### Running the app in "Nightly Updates" mode locally

First, ensure `mvn` is using Java8. (See instructions [in Setup](#setup) about installing & enabling Java8.) If `mvn -v` reports "Java version" other than 1.8 (e.g. "Java version: 17.0.2"), you may need to set `JAVA_HOME` when running `mvn`. Instructions follow.

You'll also need to set up a local env file. See [.env-local-export.sample](.env-local-export.sample) for a sample config file you can use for running the app locally. To use it, copy `.env-local-export.sample` to `.env-local-export` and fill in the missing values. This allows you to `source` the file into your shell and run the app:
```
source .env-local-export; mvn spring-boot:run
```

If you encounter a build/application error and/or `mvn -v` reports it's linked to a java other than 1.8, prefix the `mvn` command to specify your Java8 home:
```
source .env-local-export -export; JAVA_HOME=/usr/local/opt/openjdk@8 mvn spring-boot:run
```

Note that `mvn spring-boot:run` also auto-compiles any changes you've made, so there's no need to run `mvn clean package` before running the above.

### "Bulk" Mode

This is for the initial load of data. This mode is untested since launch and is unlikely to be necessary in the short term.

TODO: note saying that this requires manual downloading & unzipping from SFTP.

#### Running the app in "Initial Load" mode locally

The following environment variables need to be set. For different options to set AWS credentials, please refer to http://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html.

```
AWS_ACCESS_KEY_ID=[used-to-publish-to-kinesis]
AWS_SECRET_ACCESS_KEY=[used-to-publish-to-kinesis]
bibSchemaAPI=https://[domain.example.com]/api/v0.1/current-schemas/BibPostRequest
itemSchemaAPI=https://[domain.example.com]/api/v0.1/current-schemas/ItemPostRequest
kinesisBibStream=[snip]
kinesisItemStream=[snip]
scsbexportstagingLocation=/var/app/current/scsbxml
```

...can we add specific IDE instructions...(or things useful to future maintainers)

## Deployment

This app is deployed automatically [by Travis](.travis.yml) when updates are made to the `qa` or `production` branch.

If you need to deploy directly, that looks something like this:

1.  `mvn clean package`
1.  `eb init Recap-Harvester --profile [profile name]`
1.  Create application

  ```bash
  eb create [nightly|initial]-recap-harvester-[environment] \
      --instance_type m3.medium \
      --instance_profile [nightly|initial]-cloudwatchable-beanstalk \
      --cname recap-harvester-[environment] \
      --single \
      --vpc.id env-vpc \
      --vpc.ec2subnets private-subnet-id-1 \
      --tags Project=Discovery,harvester=recap_harvester \
      --keyname dgdvteam \
      --envvars KEYFROMABOVE="value",KEYFROMABOVE2="value" \
      --profile your-aws-profile-name
  ```

## Contributing

This repo uses the [Main-QA-Production Git Workflow](https://github.com/NYPL/engineering-general/blob/master/standards/git-workflow.md#main-qa-production)
